p8105_hw_nkr2121
================
Nihaal Rahman

## Problem 1

Let’s begin by loading in pols_month data set and cleaning it up.

``` r
pols <- read_csv("~/Documents/Columbia/Semester 3/Data1/fivethirtyeight_datasets/pols-month.csv") |> 
  separate(mon, into = c("year", "month", "day"), sep = '-') |> 
  mutate(month = month.name[as.numeric(month)],
         year = as.numeric(year),
         president = case_when(
           as.numeric(prez_gop) > 0 ~ "gop",
           as.numeric(prez_dem) > 0 ~ "dem"
         )) |> 
  select(-c("prez_dem", "prez_gop", "day"))
```

Now moving on to the snp data set.

``` r
snp <- read_csv("~/Documents/Columbia/Semester 3/Data1/fivethirtyeight_datasets/snp.csv") |> 
  separate(date, into = c("month", "day", "year"), sep = '/') |> 
  mutate(year = as.numeric(year),
         year = case_when(
           year < 23 ~ 2000 + year),
         month = month.name[as.numeric(month)]) |> 
  arrange("year", "month") |> 
  select(c("year", "month", "close"))
```

Now moving onto the unemployment data set.

``` r
unemployment <- read_csv("~/Documents/Columbia/Semester 3/Data1/fivethirtyeight_datasets/unemployment.csv") |> 
  janitor::clean_names() |> 
  pivot_longer(
    cols = c("jan","feb", "mar", "apr", "may", "jun", "jul", "aug", "sep", "oct", "nov", "dec"),
    names_to = "month",
    values_to = "unemployment_rate") |> 
  mutate(year = as.numeric(year),
         month = case_match(
    month,
    "jan" ~ "January",
    "feb" ~ "February",
    "mar" ~ "March",
    "apr" ~ "April",
    "may" ~ "May",
    "jun" ~ "June",
    "jul" ~ "July",
    "aug" ~ "August",
    "sep" ~ "September",
    "oct" ~ "October",
    "nov" ~ "November",
    "dec" ~ "December"
    ))
```

Now I will merge the datasets together.

``` r
problem1 = left_join(pols, snp, by=c("year","month")) |> 
  left_join(unemployment, by=c("year","month"))
```

In the first step, we pulled in and cleaned the the pols data set. After
cleaning, this data set has 9 variables: year, month, gov_gop, sen_gop,
rep_gop, gov_dem, sen_dem, rep_dem, and president. The year and month
variables tell us when the count was recorded. The gov_gop and gov_dem
variables tell us how many governors were republicans or democrats,
respectively, when the count was taken. The sen_gop and sen_dem
variables tell us how many senators were republicans or democrats,
respectively, when the count was taken. The rep_gop and rep_dem
variables tell us how many house members were republicans or democrats,
respectively, whe nthe count was taken. Finally, the president variable
tells us if the president at the time was republican or democrat when
the count was taken.

In the next step, we pulled in and cleaned the snp data set. After
cleaning, this data set has 3 variables: year, month, and close. The
year and month variables tell us when the observation was taken, and the
close variable tells us the closing values of the S&P stock index on the
associated date.

In the following step, we pulled in and cleaned the unemployment data
set. After cleaning, this data set has 3 variables: year, month, and
unemployment_rate. The year and month variables tell us the date of
observation, and the unemployement_rate variable tells us the percentage
of unemployment on the given year/month

I then merged these 3 data sets into a new data set titled “problem1”.
This dataset has 11 variables (year, month, gov_gop, sen_gop, rep_gop,
gov_dem, sen_dem, rep_dem, president, close, unemployment_rate). This
dataset has 822 rows, and the range of years in this data set is 1947 to
2015.

## Problem 2

First, importing the Mr. Trashwheel data

``` r
mrtrashwheel = read_excel("~/Documents/Columbia/Semester 3/Data1/202309 Trash Wheel Collection Data.xlsx", sheet = "Mr. Trash Wheel", range = "A2:N586") |> 
  janitor::clean_names() |> 
  mutate(name = "mrtrash",
         homes_powered = (weight_tons * 500) / 30)
```

Next, doing the same for Professor Trashwheel

``` r
proftrashwheel = read_excel("~/Documents/Columbia/Semester 3/Data1/202309 Trash Wheel Collection Data.xlsx", sheet = "Professor Trash Wheel", range = "A2:M108") |> 
  janitor::clean_names() |> 
  mutate(name = "proftrash",
         homes_powered = (weight_tons * 500) / 30)
```

Finally, doing the same for Gwynnda

``` r
gwynnda = read_excel("~/Documents/Columbia/Semester 3/Data1/202309 Trash Wheel Collection Data.xlsx", sheet = "Gwynnda Trash Wheel", range = "A2:L157") |> 
  janitor::clean_names() |> 
  mutate(name = "gwynnda",
         homes_powered = (weight_tons * 500) / 30)
```

Now I will merge the data sets

``` r
mrtrashwheel = mrtrashwheel |> mutate(
  year = as.numeric(year))

problem2 = bind_rows(mrtrashwheel, proftrashwheel, gwynnda)
```

The combined data set problem 2 has 845 observations and 15 variables.
Some key variables are name (name of the trash wheel), weight_tons
(amount of total litter in tons), and the houses powered (# of houses
powered).

The total weight of trash collected by Professor Trash Wheel was 216.26
tons.

The total number of cigarette butts collected by Gwynnda in July of 2021
was 16300 butts.

## Problem 3

Importing baseline data set.

``` r
baseline = read_csv("~/Documents/Columbia/Semester 3/Data1/data_mci/MCI_baseline.csv", 
                     skip = 1) |> 
  janitor::clean_names() |> 
   mutate(
    sex = case_match(  
      sex,
      1 ~ "male",
      0 ~ "female"
    ),
    apoe4 = case_match(
      apoe4,
      1 ~ "carrier",
      0 ~ "non-carrier"
    ),
       age_at_onset = if_else(
         age_at_onset == ".", NA, as.numeric(age_at_onset))) |> 
      filter(age_at_onset > as.numeric(current_age) | is.na(age_at_onset))
```

Some important steps in cleaning this data set were skipping 1 row,
because there were two rows used to describe the variables in the data
set; re-coding the sex and apoe4 variables to have more descriptive,
character-values; and filtering the data set to remove those
observations where the onset age came before the participant’s current
age (did not want MCI at baseline).

The average baseline age is 65.03 years.

The proportion of women in the study who are APOE4 carriers is 0.3
(63/210).

Importing the amyloid dataset.

``` r
amyloid <- read_csv("~/Documents/Columbia/Semester 3/Data1/data_mci/mci_amyloid.csv", 
    skip = 1) |> 
  janitor::clean_names() |> 
  rename(id = study_id)
```

Important steps in importing the amyloid data set is to skip 1 row,
because there were two rows used to describe the variables in the data
set and renaming the id column to match that of the baseline data set.

Seeing which participants appear in only the baseline data set.

``` r
anti_join(baseline, amyloid, by = "id")
```

    ## # A tibble: 8 × 6
    ##      id current_age sex    education apoe4       age_at_onset
    ##   <dbl>       <dbl> <chr>      <dbl> <chr>              <dbl>
    ## 1    14        58.4 female        20 non-carrier         66.2
    ## 2    49        64.7 male          16 non-carrier         68.4
    ## 3    92        68.6 female        20 non-carrier         NA  
    ## 4   179        68.1 male          16 non-carrier         NA  
    ## 5   268        61.4 female        18 carrier             67.5
    ## 6   304        63.8 female        16 non-carrier         NA  
    ## 7   389        59.3 female        16 non-carrier         NA  
    ## 8   412        67   male          16 carrier             NA

Participant ID’s 14, 49, 92, 179, 268, 304, 389, 412 appear in the
baseline data set, but not the amyloid one.

Seeing which participants appear in only the amyloid data set.

``` r
anti_join(amyloid, baseline, by = "id")
```

    ## # A tibble: 16 × 6
    ##       id baseline    time_2      time_4      time_6      time_8     
    ##    <dbl> <chr>       <chr>       <chr>       <chr>       <chr>      
    ##  1    72 0.106965463 <NA>        0.107266218 0.106665207 <NA>       
    ##  2   234 0.110521689 0.110988335 0.110318671 0.107334344 0.108868811
    ##  3   283 0.113436336 0.106568976 0.11338643  0.10820706  0.114399611
    ##  4   380 0.111158847 0.104560429 0.106822683 0.104961175 0.109506164
    ##  5   484 0.11139422  0.110936838 0.109182887 0.110607585 0.107057538
    ##  6   485 0.106042813 0.105158363 0.107758828 0.107281321 0.106181816
    ##  7   486 0.109161071 0.114634379 <NA>        0.110035156 0.107234758
    ##  8   487 0.110821971 0.107791347 0.109855229 0.110951271 0.105861634
    ##  9   488 0.110418756 0.111994328 0.113132987 0.108902038 0.109449907
    ## 10   489 0.11477384  0.113322128 0.115109381 0.116004489 0.112260161
    ## 11   490 0.111762756 0.109627815 0.111492905 0.110104053 <NA>       
    ## 12   491 0.116934974 0.113763228 0.111358448 0.110509854 0.110541984
    ## 13   492 0.109757685 0.109912273 0.110672861 0.109064952 0.109161341
    ## 14   493 0.108357146 0.108161281 0.109491179 0.104448142 0.108636703
    ## 15   494 0.116669151 0.109711076 0.112133216 0.111399722 0.108836759
    ## 16   495 Na          0.105142354 0.108149625 0.105918659 0.102512562

Participant ID’s 72, 234, 283, 380, 484, 485, 486, 487, 488, 489, 490,
491, 492, 493, 494, 495 appear in the baseline data set, but not the
amyloid one.
